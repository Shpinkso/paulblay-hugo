<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>AI on Paul Blay</title><link>https://shpinkso.github.io/paulblay-hugo/previews/main/tags/ai/</link><description>Recent content in AI on Paul Blay</description><generator>Hugo -- gohugo.io</generator><language>en-gb</language><lastBuildDate>Tue, 07 Oct 2025 08:52:20 +0100</lastBuildDate><atom:link href="https://shpinkso.github.io/paulblay-hugo/previews/main/tags/ai/index.xml" rel="self" type="application/rss+xml"/><item><title>A Policy for AI enhanced software development</title><link>https://shpinkso.github.io/paulblay-hugo/previews/main/blog/2025/10/07/ai_in_software_development/</link><pubDate>Tue, 07 Oct 2025 08:52:20 +0100</pubDate><guid>https://shpinkso.github.io/paulblay-hugo/previews/main/blog/2025/10/07/ai_in_software_development/</guid><description>The DORA research group at Google recently came out with an AI capabilities model and capability number 1 is to have a &amp;ldquo;Clear and communicated AI stance&amp;rdquo;. Given my experience so far talking to other leaders and on the ground, here&amp;rsquo;s my proposal for what an effective AI stance could look like:
Core Philosophy LLMs should amplify engineering cognition, not automate it
Human Ownership: Engineers must remain the authors and owners of production logic.</description></item></channel></rss>